"""å®¡è®¡é¡µé¢ â€” AI çº¢é˜Ÿå®¡è®¡å‘¨æœŸåˆ†æç»“æœ"""

from __future__ import annotations

import json
import re
from datetime import datetime
from pathlib import Path

import streamlit as st

from quant.llm.client import SiliconFlowClient, LLMConfig, LLMError
from quant.llm.prompts import (
    build_audit_prompt, build_audit_chat_messages,
    build_factor_chat_messages,
    build_cycle_chat_messages,
    build_audit_param_prompt,
)
from quant.dashboard.llm_settings import get_audit_llm_config
from quant.dashboard.sector_factors import extract_json_from_text, validate_factors

# ==================== è·¯å¾„å¸¸é‡ ====================

_ROOT = Path(__file__).parent.parent.parent
CYCLE_DATA_PATH = _ROOT / "data" / "cycle_analysis.json"
FACTORS_PATH = _ROOT / "data" / "sector_factors.json"
PROFILES_DIR = _ROOT / "data" / "stock_profiles"
RESEARCH_DIR = _ROOT / "data" / "research"
AUDIT_RESULTS_PATH = _ROOT / "data" / "audit_results.json"

# å®¡è®¡ç±»å‹å®šä¹‰
_AUDIT_TYPES = {
    "factors": "å› å­å®¡è®¡",
    "cycle": "å‘¨æœŸå®¡è®¡",
    "stock": "ä¸ªè‚¡å®¡è®¡",
    "full": "å…¨é¢å®¡è®¡",
}


# ==================== æŒä¹…åŒ– ====================

def _load_audit_results() -> dict:
    """åŠ è½½æ‰€æœ‰å®¡è®¡ç»“æœï¼Œè‡ªåŠ¨è¿ç§»æ—§æ ¼å¼"""
    if not AUDIT_RESULTS_PATH.exists():
        return {}
    try:
        with open(AUDIT_RESULTS_PATH, "r", encoding="utf-8") as f:
            raw = json.load(f)
    except Exception:
        return {}

    migrated = False
    _KNOWN_TYPES = {"factors", "cycle", "stock", "full"}
    for sector, data in list(raw.items()):
        # æ—§æ ¼å¼æ£€æµ‹ï¼šæœ‰æ—§ key ä¸”æ²¡æœ‰æ–°ç±»å‹ key
        has_old_keys = "report" in data or "raw_response" in data
        has_new_keys = bool(set(data.keys()) & _KNOWN_TYPES)
        if has_old_keys and not has_new_keys:
            raw[sector] = {"full": data}
            migrated = True

    if migrated:
        AUDIT_RESULTS_PATH.parent.mkdir(parents=True, exist_ok=True)
        with open(AUDIT_RESULTS_PATH, "w", encoding="utf-8") as f:
            json.dump(raw, f, ensure_ascii=False, indent=2)

    return raw


def _save_audit_result(sector: str, audit_type: str, audit_data: dict) -> None:
    """ä¿å­˜å•ä¸ªæ¿å—æŸç±»å‹çš„å®¡è®¡ç»“æœ"""
    all_results = _load_audit_results()
    audit_data["audited_at"] = datetime.now().isoformat(timespec="seconds")
    if sector not in all_results:
        all_results[sector] = {}
    all_results[sector][audit_type] = audit_data
    AUDIT_RESULTS_PATH.parent.mkdir(parents=True, exist_ok=True)
    with open(AUDIT_RESULTS_PATH, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)


# ==================== æ•°æ®åŠ è½½ ====================

def _load_sector_complete_data(sector: str) -> dict:
    """åŠ è½½æ¿å—çš„æ‰€æœ‰åˆ†ææ•°æ®ï¼ˆå› å­+å‘¨æœŸ+ä¸ªè‚¡+å½’æ¡£ï¼‰"""
    data = {"sector": sector, "found": False}

    # 1. å› å­é…ç½®
    if FACTORS_PATH.exists():
        try:
            with open(FACTORS_PATH, "r", encoding="utf-8") as f:
                all_factors = json.load(f)
                if sector in all_factors:
                    data["factors_config"] = all_factors[sector]
                    data["found"] = True
        except Exception:
            pass

    # 2. å‘¨æœŸåˆ†æç»“æœ
    if CYCLE_DATA_PATH.exists():
        try:
            with open(CYCLE_DATA_PATH, "r", encoding="utf-8") as f:
                all_cycles = json.load(f)
                if sector in all_cycles:
                    data["cycle_analysis"] = all_cycles[sector]
                    data["found"] = True
        except Exception:
            pass

    # 3. ä¸ªè‚¡æ¡£æ¡ˆ
    safe_name = sector.replace("/", "_").replace("\\", "_")
    profile_path = PROFILES_DIR / f"{safe_name}.json"
    if profile_path.exists():
        try:
            with open(profile_path, "r", encoding="utf-8") as f:
                data["stock_profiles"] = json.load(f)
        except Exception:
            pass

    # 4. å½’æ¡£ç ”ç©¶æ•°æ®ï¼ˆæ‰¾æœ€æ–°çš„ï¼‰
    sector_research_dir = RESEARCH_DIR / re.sub(r'[\\/:*?"<>|]', "_", sector)
    if sector_research_dir.exists():
        subdirs = sorted(
            [d for d in sector_research_dir.iterdir() if d.is_dir()], reverse=True,
        )
        if subdirs:
            latest = subdirs[0]
            archive_files = list(latest.glob("*"))
            data["archive_path"] = str(latest)
            data["archive_file_count"] = len(archive_files)

    return data


# ==================== JSON è§£æ ====================

def _parse_audit_json(text: str) -> dict | None:
    """ä» LLM å›å¤ä¸­æå–å®¡è®¡æŠ¥å‘Š JSON"""
    m = re.search(r"```json\s*\n?(.*?)\n?\s*```", text, re.DOTALL)
    if m:
        try:
            return json.loads(m.group(1))
        except json.JSONDecodeError:
            pass
    # å›é€€ï¼šç”¨å¹³è¡¡æ‹¬å·æå– JSON å¯¹è±¡
    start = text.find("{")
    if start != -1:
        depth = 0
        for i in range(start, len(text)):
            if text[i] == "{":
                depth += 1
            elif text[i] == "}":
                depth -= 1
                if depth == 0:
                    candidate = text[start : i + 1]
                    try:
                        obj = json.loads(candidate)
                        if "risk_level" in obj:
                            return obj
                    except json.JSONDecodeError:
                        pass
                    break
    return None


# ==================== æ¸²æŸ“ç»„ä»¶ ====================

_RISK_COLORS = {"low": "green", "medium": "orange", "high": "red", "critical": "red"}
_RISK_LABELS = {"low": "ä½é£é™©", "medium": "ä¸­ç­‰é£é™©", "high": "é«˜é£é™©", "critical": "ä¸¥é‡é£é™©"}


def _render_audit_report(report: dict) -> None:
    """æ¸²æŸ“ç»“æ„åŒ–å®¡è®¡æŠ¥å‘Š"""
    overall_risk = report.get("risk_level", "medium")
    color = _RISK_COLORS.get(overall_risk, "gray")
    label = _RISK_LABELS.get(overall_risk, "æœªçŸ¥")

    # æ€»ä½“é£é™©
    col1, col2 = st.columns([2, 2])
    with col1:
        st.markdown(f"### æ•´ä½“é£é™©: :{color}[**{label}**]")
    with col2:
        confidence = report.get("confidence_score", 0)
        st.metric("åˆ†æå¯ä¿¡åº¦", f"{confidence}%")

    summary = report.get("summary", "")
    if summary:
        st.markdown(summary)

    st.markdown("---")

    # åˆ†é¡¹å®¡è®¡ç»“æœ
    st.subheader("åˆ†é¡¹å®¡è®¡ç»“æœ")
    items = report.get("audit_items", [])
    for item in items:
        category = item.get("category", "æœªçŸ¥")
        finding = item.get("finding", "")
        risk = item.get("risk", "medium")
        recommendation = item.get("recommendation", "")
        risk_color = _RISK_COLORS.get(risk, "gray")
        risk_label = _RISK_LABELS.get(risk, "æœªçŸ¥")

        with st.expander(
            f":{risk_color}[**{category}**] â€” {risk_label}",
            expanded=(risk in ("high", "critical")),
        ):
            st.markdown(f"**å‘ç°:** {finding}")
            if recommendation:
                st.markdown(f"**å»ºè®®:** {recommendation}")

    # çº¢æ——ä¿¡å·
    red_flags = report.get("red_flags", [])
    if red_flags:
        st.markdown("---")
        st.subheader("é‡ç‚¹å…³æ³¨")
        for flag in red_flags:
            st.error(flag)

    # æ•°æ®è´¨é‡é—®é¢˜
    data_issues = report.get("data_quality_issues", [])
    if data_issues:
        st.markdown("---")
        st.subheader("æ•°æ®è´¨é‡é—®é¢˜")
        for issue in data_issues:
            st.warning(issue)

    # LLM å¹»è§‰æŒ‡æ ‡
    hallucinations = report.get("llm_hallucination_indicators", [])
    if hallucinations:
        st.markdown("---")
        st.subheader("LLM å¹»è§‰å«Œç–‘")
        for h in hallucinations:
            st.warning(h)

    # ä¸åŒè§£è¯»
    alt = report.get("alternative_interpretations", [])
    if alt:
        st.markdown("---")
        st.subheader("å…¶ä»–å¯èƒ½çš„è§£è¯»")
        for a in alt:
            st.info(a)


def _render_audit_chat(
    sector: str, audit_type: str, llm_config: LLMConfig, audit_data: dict,
) -> None:
    """å®¡è®¡å¯¹è¯åŒº â€” è¿½é—®å®¡è®¡ agent"""
    msg_key = f"audit_chat_{sector}_{audit_type}_messages"

    if msg_key not in st.session_state:
        st.session_state[msg_key] = audit_data.get("conversation", [])

    messages: list[dict] = st.session_state[msg_key]

    # å±•ç¤ºå†å²
    for msg in messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    pending_key = f"_pending_audit_chat_{sector}_{audit_type}"
    user_input = st.chat_input(
        f"å‘å®¡è®¡ agent æé—®...", key=f"audit_chat_input_{sector}_{audit_type}",
    )
    if user_input:
        messages.append({"role": "user", "content": user_input})
        st.session_state[pending_key] = True
        st.rerun()

    if not st.session_state.get(pending_key):
        return

    # æ„å»ºå¯¹è¯è¯·æ±‚
    last_user_msg = messages[-1]["content"] if messages and messages[-1]["role"] == "user" else ""
    llm_messages = build_audit_chat_messages(sector, audit_data, messages[:-1], last_user_msg)

    from quant.dashboard.bg_task import bg_llm_stream, clear_task
    task_id = f"audit_chat_{sector}_{audit_type}"
    with st.chat_message("assistant"):
        full_reply = bg_llm_stream(task_id, llm_config, llm_messages, retry_key=f"retry_audit_chat_{sector}_{audit_type}")

    if full_reply is None:
        return

    messages.append({"role": "assistant", "content": full_reply})

    if len(messages) > 40:
        messages = messages[-40:]
    st.session_state[msg_key] = messages

    # æŒä¹…åŒ–å¯¹è¯
    audit_data["conversation"] = messages
    _save_audit_result(sector, audit_type, audit_data)
    st.session_state.pop(pending_key, None)
    clear_task(task_id)


# ==================== å®¡è®¡é—­ç¯åé¦ˆ ====================

_TYPE_LABELS = {"factors": "å› å­é…ç½®", "cycle": "å‘¨æœŸåˆ†æ", "stock": "ä¸ªè‚¡æ¡£æ¡ˆ"}


def _build_feedback_message(audit_type: str, report: dict) -> str:
    """ä»å®¡è®¡æŠ¥å‘Šä¸­æå– high/critical å‘ç°ï¼Œæ ¼å¼åŒ–ä¸ºä¿®æ­£å»ºè®®æ¶ˆæ¯"""
    type_label = _TYPE_LABELS.get(audit_type, audit_type)
    risk_level = _RISK_LABELS.get(report.get("risk_level", "medium"), "ä¸­ç­‰é£é™©")
    confidence = report.get("confidence_score", 0)

    lines = [
        f"ä»¥ä¸‹æ˜¯ç‹¬ç«‹å®¡è®¡ agent å¯¹æœ¬æ¿å—çš„{type_label}å®¡è®¡ç»“æœ"
        f"ï¼ˆé£é™©ç­‰çº§: {risk_level}ï¼Œå¯ä¿¡åº¦: {confidence}%ï¼‰ï¼š",
        "",
        "ã€å®¡è®¡å‘ç°ã€‘",
    ]

    for i, item in enumerate(report.get("audit_items", []), 1):
        category = item.get("category", "æœªçŸ¥")
        finding = item.get("finding", "")
        recommendation = item.get("recommendation", "")
        lines.append(f"{i}. {category}: {finding}")
        if recommendation:
            lines.append(f"   å»ºè®®: {recommendation}")

    red_flags = report.get("red_flags", [])
    if red_flags:
        lines.append("")
        lines.append("ã€çº¢æ——ä¿¡å·ã€‘")
        for flag in red_flags:
            lines.append(f"- {flag}")

    lines.append("")
    lines.append(
        "è¯·æ ¹æ®ä»¥ä¸Šå®¡è®¡æ„è§ï¼Œè¯„ä¼°å½“å‰åˆ†ææ˜¯å¦éœ€è¦ä¿®æ­£ã€‚"
        "å¦‚æœéœ€è¦ä¿®æ­£ï¼Œè¯·è¾“å‡ºä¿®æ­£åçš„å®Œæ•´ JSONã€‚"
        "å¦‚æœè®¤ä¸ºå®¡è®¡æ„è§ä¸åˆç†ï¼Œè¯·è¯´æ˜ç†ç”±ã€‚"
    )
    return "\n".join(lines)


def _inject_and_respond(
    sector: str, audit_type: str, feedback_msg: str, llm_config: LLMConfig,
) -> tuple[str | None, str]:
    """æ ¸å¿ƒé—­ç¯å‡½æ•°ï¼šå°†å®¡è®¡åé¦ˆæ³¨å…¥åˆ°æºç³»ç»Ÿå¹¶è·å– LLM å›å¤ã€‚

    Returns:
        (reply_text | None, status_msg)
    """
    client = SiliconFlowClient(llm_config)

    if audit_type == "factors":
        return _inject_factors(sector, feedback_msg, client)
    elif audit_type == "cycle":
        return _inject_cycle(sector, feedback_msg, client)
    elif audit_type == "stock":
        return _inject_stock(sector, feedback_msg)
    return None, "æœªçŸ¥å®¡è®¡ç±»å‹"


def _inject_factors(
    sector: str, feedback_msg: str, client: SiliconFlowClient,
) -> tuple[str | None, str]:
    """å› å­å®¡è®¡é—­ç¯ï¼šæ³¨å…¥åé¦ˆåˆ° sector_factors.json"""
    if not FACTORS_PATH.exists():
        return None, "å› å­é…ç½®æ–‡ä»¶ä¸å­˜åœ¨"

    with open(FACTORS_PATH, "r", encoding="utf-8") as f:
        all_factors = json.load(f)

    sector_data = all_factors.get(sector)
    if not sector_data:
        return None, f"æ¿å—ã€Œ{sector}ã€æ— å› å­é…ç½®"

    factors_json = json.dumps(sector_data.get("factors", []), ensure_ascii=False, indent=2)
    history = sector_data.get("conversation", [])

    messages = build_factor_chat_messages(sector, factors_json, history, feedback_msg)
    try:
        reply = client.chat(messages)
    except LLMError as e:
        return None, f"LLM è°ƒç”¨å¤±è´¥: {e}"

    # è¿½åŠ å¯¹è¯åˆ° conversation
    history.append({"role": "user", "content": feedback_msg})
    history.append({"role": "assistant", "content": reply})
    if len(history) > 40:
        history = history[-40:]
    sector_data["conversation"] = history

    # å°è¯•ä»å›å¤ä¸­æå–ä¿®æ­£åçš„å› å­ JSON
    status_msg = "AI å·²è¯„ä¼°å®¡è®¡å»ºè®®"
    parsed = extract_json_from_text(reply)
    if parsed:
        valid = validate_factors(parsed)
        if valid:
            sector_data["factors"] = valid
            sector_data["updated_at"] = datetime.now().isoformat(timespec="seconds")
            status_msg = "å·²è‡ªåŠ¨æ›´æ–°å› å­é…ç½®"

    all_factors[sector] = sector_data
    with open(FACTORS_PATH, "w", encoding="utf-8") as f:
        json.dump(all_factors, f, ensure_ascii=False, indent=2)

    return reply, status_msg


def _inject_cycle(
    sector: str, feedback_msg: str, client: SiliconFlowClient,
) -> tuple[str | None, str]:
    """å‘¨æœŸå®¡è®¡é—­ç¯ï¼šæ³¨å…¥åé¦ˆåˆ° cycle_analysis.json"""
    if not CYCLE_DATA_PATH.exists():
        return None, "å‘¨æœŸåˆ†ææ–‡ä»¶ä¸å­˜åœ¨"

    with open(CYCLE_DATA_PATH, "r", encoding="utf-8") as f:
        all_cycles = json.load(f)

    sector_data = all_cycles.get(sector)
    if not sector_data:
        return None, f"æ¿å—ã€Œ{sector}ã€æ— å‘¨æœŸåˆ†ææ•°æ®"

    history = sector_data.get("conversation", [])

    messages = build_cycle_chat_messages(sector, sector_data, history, feedback_msg)
    try:
        reply = client.chat(messages)
    except LLMError as e:
        return None, f"LLM è°ƒç”¨å¤±è´¥: {e}"

    # è¿½åŠ å¯¹è¯
    history.append({"role": "user", "content": feedback_msg})
    history.append({"role": "assistant", "content": reply})
    if len(history) > 40:
        history = history[-40:]
    sector_data["conversation"] = history

    # å°è¯•ä»å›å¤ä¸­æå–ä¿®æ­£åçš„å‘¨æœŸåˆ†æ JSON
    status_msg = "AI å·²è¯„ä¼°å®¡è®¡å»ºè®®"
    m = re.search(r"```json\s*\n?(.*?)\n?\s*```", reply, re.DOTALL)
    candidate = None
    if m:
        try:
            candidate = json.loads(m.group(1))
        except json.JSONDecodeError:
            pass
    if candidate is None:
        start = reply.find("{")
        if start != -1:
            depth = 0
            for i in range(start, len(reply)):
                if reply[i] == "{":
                    depth += 1
                elif reply[i] == "}":
                    depth -= 1
                    if depth == 0:
                        try:
                            candidate = json.loads(reply[start : i + 1])
                        except json.JSONDecodeError:
                            pass
                        break

    if candidate:
        if "overall" in candidate:
            # LLM è¿”å›äº†å®Œæ•´ç»“æ„ {"overall": {...}, ...}
            preserved_keys = {"news", "archive_path", "analyzed_at", "factors", "conversation"}
            for key in preserved_keys:
                if key in sector_data and key not in candidate:
                    candidate[key] = sector_data[key]
            sector_data.update(candidate)
            status_msg = "å·²è‡ªåŠ¨æ›´æ–°å‘¨æœŸåˆ†æ"
        elif "cycle_position" in candidate:
            # LLM è¿”å›äº† overall å†…éƒ¨çš„å­—æ®µ {"cycle_position": ..., "reversal_probability": ...}
            # éœ€è¦æ¸…ç† reversal_probability å¯èƒ½ä¸ºå­—ç¬¦ä¸²ï¼ˆå¦‚ "60%"ï¼‰çš„æƒ…å†µ
            rp = candidate.get("reversal_probability", 0)
            if isinstance(rp, str):
                rp = int("".join(c for c in rp if c.isdigit()) or "0")
                candidate["reversal_probability"] = rp
            if "overall" not in sector_data:
                sector_data["overall"] = {}
            sector_data["overall"].update(candidate)
            status_msg = "å·²è‡ªåŠ¨æ›´æ–°å‘¨æœŸåˆ†æ"

    all_cycles[sector] = sector_data
    with open(CYCLE_DATA_PATH, "w", encoding="utf-8") as f:
        json.dump(all_cycles, f, ensure_ascii=False, indent=2)

    return reply, status_msg


def _inject_stock(sector: str, feedback_msg: str = "") -> tuple[None, str]:
    """ä¸ªè‚¡å®¡è®¡é—­ç¯ï¼šåˆ æ—§åˆ†æ + æ¸…ç¼“å­˜ + æ³¨å…¥å®¡è®¡ä¸Šä¸‹æ–‡"""
    from quant.data.cache import DataCache

    safe_name = sector.replace("/", "_").replace("\\", "_")
    profile_path = PROFILES_DIR / f"{safe_name}.json"

    # æ¸…é™¤ PB ç¼“å­˜
    cleared_count = 0
    if profile_path.exists():
        try:
            with open(profile_path, "r", encoding="utf-8") as f:
                old_data = json.load(f)
            cache = DataCache()
            for s in old_data.get("stocks", []):
                code = s.get("code", "")
                if code:
                    cache.clear_pattern(f"pb_%{code}%")
                    cleared_count += 1
        except Exception:
            pass
        profile_path.unlink()

    st.session_state["pending_stock_reanalysis"] = sector
    st.session_state["stock_reanalysis_context"] = feedback_msg  # ä¿å­˜å®¡è®¡æ„è§ä¾›é‡åˆ†æå‚è€ƒ
    return None, f"å·²æ¸…é™¤æ—§åˆ†æï¼ˆ{cleared_count} åªè‚¡ç¥¨ç¼“å­˜ï¼‰ï¼Œåˆ‡æ¢åˆ°ã€Œä¸ªè‚¡æ¡£æ¡ˆã€å°†è‡ªåŠ¨é‡åˆ†æï¼ˆå«å®¡è®¡æ„è§ï¼‰"


def _render_feedback_action(
    sector: str, audit_type: str, report: dict, llm_config: LLMConfig,
) -> None:
    """åœ¨å®¡è®¡æŠ¥å‘Šä¸‹æ–¹æ¸²æŸ“åé¦ˆåŒºåŸŸ"""
    from quant.dashboard.bg_task import has_task

    st.markdown("#### å®¡è®¡å»ºè®®å›ä¼ ")

    if audit_type == "full":
        # å…¨é¢å®¡è®¡æ˜¾ç¤ºä¸‰ä¸ªç‹¬ç«‹æŒ‰é’®
        _render_full_feedback_buttons(sector, report, llm_config)
        return

    # å•ç±»å‹å®¡è®¡
    feedback_msg = _build_feedback_message(audit_type, report)

    feedback_msg = st.text_area(
        "ä¿®æ­£å»ºè®®ï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=feedback_msg,
        height=200,
        key=f"feedback_msg_{sector}_{audit_type}",
    )

    btn_labels = {
        "factors": "å‘é€åˆ°ã€Œå› å­é…ç½®ã€ä¿®æ­£",
        "cycle": "å‘é€åˆ°ã€Œå‘¨æœŸåˆ†æã€ä¿®æ­£",
        "stock": "è§¦å‘ä¸ªè‚¡é‡æ–°åˆ†æ",
    }
    btn_label = btn_labels.get(audit_type, "å‘é€ä¿®æ­£")

    fb_task_id = f"audit_fb_{audit_type}_{sector}"
    fb_active = has_task(fb_task_id)
    fb_pending_key = f"_fb_pending_{audit_type}_{sector}"

    # æ´»è·ƒä»»åŠ¡è½®è¯¢ï¼ˆåœ¨æŒ‰é’®ä¹‹å‰ï¼Œé˜²æ­¢ rerun åä¸¢å¤±ï¼‰
    if fb_active or st.session_state.get(fb_pending_key):
        _execute_feedback(sector, audit_type, feedback_msg, llm_config)
        return

    if st.button(btn_label, type="primary", key=f"feedback_btn_{sector}_{audit_type}"):
        st.session_state[fb_pending_key] = True
        st.rerun()


def _render_full_feedback_buttons(
    sector: str, report: dict, llm_config: LLMConfig,
) -> None:
    """å…¨é¢å®¡è®¡ â€” æ˜¾ç¤ºä¸‰ä¸ªç‹¬ç«‹åé¦ˆæŒ‰é’®"""
    from quant.dashboard.bg_task import has_task

    feedback_msg = _build_feedback_message("full", report)

    feedback_msg = st.text_area(
        "ä¿®æ­£å»ºè®®ï¼ˆå¯ç¼–è¾‘ï¼‰",
        value=feedback_msg,
        height=200,
        key=f"feedback_msg_{sector}_full",
    )

    col1, col2, col3 = st.columns(3)

    # æ£€æŸ¥å„ç³»ç»Ÿæ•°æ®æ˜¯å¦å­˜åœ¨
    has_factors = FACTORS_PATH.exists() and sector in (
        json.loads(FACTORS_PATH.read_text(encoding="utf-8")) if FACTORS_PATH.exists() else {}
    )
    has_cycle = CYCLE_DATA_PATH.exists() and sector in (
        json.loads(CYCLE_DATA_PATH.read_text(encoding="utf-8")) if CYCLE_DATA_PATH.exists() else {}
    )
    safe_name = sector.replace("/", "_").replace("\\", "_")
    has_stock = (PROFILES_DIR / f"{safe_name}.json").exists()

    # å„åé¦ˆæŒ‰é’®çš„åå°ä»»åŠ¡çŠ¶æ€
    fb_types = [("factors", has_factors, col1), ("cycle", has_cycle, col2), ("stock", has_stock, col3)]
    fb_btn_labels = {
        "factors": "å‘é€åˆ°ã€Œå› å­é…ç½®ã€ä¿®æ­£",
        "cycle": "å‘é€åˆ°ã€Œå‘¨æœŸåˆ†æã€ä¿®æ­£",
        "stock": "è§¦å‘ä¸ªè‚¡é‡æ–°åˆ†æ",
    }

    # å…ˆæ£€æŸ¥æ˜¯å¦æœ‰æ´»è·ƒçš„åé¦ˆä»»åŠ¡ï¼ˆåœ¨æŒ‰é’®ä¹‹å‰è½®è¯¢ï¼‰
    any_active = False
    for target_type, has_data, _ in fb_types:
        if not has_data:
            continue
        fb_task_id = f"audit_fb_{target_type}_{sector}"
        fb_active = has_task(fb_task_id)
        fb_pending_key = f"_fb_pending_{target_type}_{sector}"
        if fb_active or st.session_state.get(fb_pending_key):
            _execute_feedback(sector, target_type, feedback_msg, llm_config)
            any_active = True

    if any_active:
        return

    # æ— æ´»è·ƒä»»åŠ¡æ—¶æ¸²æŸ“æŒ‰é’®
    for target_type, has_data, col in fb_types:
        with col:
            if has_data:
                fb_pending_key = f"_fb_pending_{target_type}_{sector}"
                if st.button(fb_btn_labels[target_type], key=f"full_fb_{target_type}_{sector}"):
                    st.session_state[fb_pending_key] = True
                    st.rerun()
            else:
                st.caption(f"æ— {_TYPE_LABELS.get(target_type, '')}æ•°æ®")


def _show_feedback_result(reply: str | None, status_msg: str, target_type: str = "") -> None:
    """å±•ç¤ºåé¦ˆæ³¨å…¥ç»“æœ"""
    if reply:
        st.markdown("**AI è¯„ä¼°ç»“æœ:**")
        st.markdown(reply)
        if "å·²è‡ªåŠ¨æ›´æ–°" in status_msg:
            st.success(status_msg)
        else:
            st.info(status_msg)
    else:
        if target_type == "stock":
            st.success(status_msg)
        else:
            st.warning(status_msg)


def _generate_param_adjustments(
    sector: str, audit_text: str, llm_config: LLMConfig,
) -> dict:
    """è°ƒç”¨ LLM æ ¹æ®å®¡è®¡æ„è§ç”Ÿæˆç»“æ„åŒ–å‚æ•°è°ƒæ•´å»ºè®®"""
    from quant.analysis.stock_cycle_analyzer import load_cycle_analysis, _select_weights

    cycle_data = load_cycle_analysis()
    sector_info = cycle_data.get(sector, {})
    overall = sector_info.get("overall", {})
    cycle_position = overall.get("cycle_position", "æœªçŸ¥")
    current_weights = _select_weights(cycle_position)
    top_n = 10

    messages = build_audit_param_prompt(sector, cycle_position, current_weights, top_n, audit_text)
    try:
        client = SiliconFlowClient(llm_config)
        reply = client.chat(messages)
    except LLMError:
        return {}

    # æå– JSON
    parsed = _parse_audit_json(reply)
    if not parsed:
        # å›é€€ï¼šå°è¯•é€šç”¨ JSON æå–
        m = re.search(r"```json\s*\n?(.*?)\n?\s*```", reply, re.DOTALL)
        if m:
            try:
                parsed = json.loads(m.group(1))
            except json.JSONDecodeError:
                return {}
        else:
            start = reply.find("{")
            if start != -1:
                depth = 0
                for i in range(start, len(reply)):
                    if reply[i] == "{":
                        depth += 1
                    elif reply[i] == "}":
                        depth -= 1
                        if depth == 0:
                            try:
                                parsed = json.loads(reply[start : i + 1])
                            except json.JSONDecodeError:
                                pass
                            break
    if not parsed:
        return {}

    # éªŒè¯ weights ä¹‹å’Œ = 1.0
    weights = parsed.get("weights")
    if weights and isinstance(weights, dict):
        total = sum(weights.values())
        if abs(total - 1.0) > 0.05:
            # è‡ªåŠ¨å½’ä¸€åŒ–
            for k in weights:
                weights[k] = round(weights[k] / total, 2)

    # éªŒè¯ top_n èŒƒå›´
    tn = parsed.get("top_n")
    if tn is not None:
        parsed["top_n"] = max(5, min(20, int(tn)))

    return parsed


def _execute_feedback(
    sector: str, target_type: str, feedback_msg: str, llm_config: LLMConfig,
) -> None:
    """æ‰§è¡Œåé¦ˆæ³¨å…¥å¹¶å±•ç¤ºç»“æœ"""
    # stock ç±»å‹ï¼šåŒæ­¥æ‰§è¡Œï¼ˆ_inject_stock åªåšæ–‡ä»¶åˆ é™¤+ç¼“å­˜æ¸…ç†ï¼Œæ¯«ç§’çº§ï¼‰
    if target_type == "stock":
        reply, status_msg = _inject_and_respond(sector, target_type, feedback_msg, llm_config)

        # LLM ç”Ÿæˆå‚æ•°è°ƒæ•´å»ºè®®
        with st.status("AI ç”Ÿæˆå‚æ•°è°ƒæ•´å»ºè®®..."):
            param_adjustments = _generate_param_adjustments(sector, feedback_msg, llm_config)

        if param_adjustments:
            st.session_state["stock_reanalysis_params"] = param_adjustments

        st.success(status_msg)
        st.session_state["_nav_redirect"] = "ğŸ“‘ ä¸ªè‚¡æ¡£æ¡ˆ"
        st.rerun()
        return

    # factors/cycleï¼šèµ° bg_runï¼ˆéœ€è¦ LLMï¼‰
    from quant.dashboard.bg_task import bg_run, clear_task

    task_id = f"audit_fb_{target_type}_{sector}"

    result = bg_run(task_id, _inject_and_respond, sector, target_type, feedback_msg, llm_config)
    if result is None:
        return

    reply, status_msg = result
    clear_task(task_id)
    st.session_state.pop(f"_fb_pending_{target_type}_{sector}", None)
    _show_feedback_result(reply, status_msg, target_type)


# ==================== å®¡è®¡æ‰§è¡Œ ====================

def _run_audit(sector: str, llm_config: LLMConfig, audit_type: str) -> None:
    """æ‰§è¡Œå®¡è®¡æµç¨‹"""
    type_label = _AUDIT_TYPES.get(audit_type, audit_type)

    # Stage 1: åŠ è½½æ•°æ®
    with st.status("åŠ è½½æ¿å—æ•°æ®...") as s1:
        data = _load_sector_complete_data(sector)

        if not data.get("found"):
            st.error(f"æ¿å—ã€Œ{sector}ã€æ— ä»»ä½•åˆ†ææ•°æ®")
            st.session_state.pop(f"_audit_pending_{audit_type}_{sector}", None)
            return

        data_summary = []
        if "factors_config" in data:
            factors = data["factors_config"].get("factors", [])
            data_summary.append(f"å› å­é…ç½®: {len(factors)} ä¸ªå› å­")
        if "cycle_analysis" in data:
            overall = data["cycle_analysis"].get("overall", {})
            data_summary.append(f"å‘¨æœŸåˆ¤æ–­: {overall.get('cycle_position', 'N/A')}")
        if "stock_profiles" in data:
            stocks = data["stock_profiles"].get("stocks", [])
            data_summary.append(f"ä¸ªè‚¡åˆ†æ: {len(stocks)} åª")
        if "archive_path" in data:
            data_summary.append(f"å½’æ¡£: {data['archive_file_count']} æ–‡ä»¶")

        for item in data_summary:
            st.caption(item)
        s1.update(label="æ•°æ®åŠ è½½å®Œæˆ", state="complete")

    # Stage 2: æ„å»ºå®¡è®¡æç¤ºè¯
    with st.status(f"å‡†å¤‡{type_label}æç¤ºè¯...") as s2:
        messages = build_audit_prompt(sector, data, audit_type)
        # ä¼°ç®— token æ•°
        total_chars = sum(len(m["content"]) for m in messages)
        st.markdown(f"**å®¡è®¡èŒƒå›´:** {len(messages)} æ¡æ¶ˆæ¯ï¼Œçº¦ {total_chars} å­—")
        st.caption(f"ç±»å‹: {type_label}")
        s2.update(label="æç¤ºè¯å·²å‡†å¤‡", state="complete")

    # Stage 3: AI å®¡è®¡åˆ†æ
    from quant.dashboard.bg_task import bg_llm_stream, clear_task
    audit_task_id = f"audit_{audit_type}_{sector}"
    full_reply = bg_llm_stream(audit_task_id, llm_config, messages, retry_key=f"retry_audit_{audit_type}_{sector}")
    if full_reply is None:
        return
    if not full_reply:
        st.error("LLM è¿”å›ç©ºå“åº”")
        clear_task(audit_task_id)
        st.session_state.pop(f"_audit_pending_{audit_type}_{sector}", None)
        return
    clear_task(audit_task_id)

    # Stage 4: è§£æå¹¶ä¿å­˜
    _finalize_audit_result(sector, audit_type, full_reply, data)


def _finalize_audit_result(
    sector: str, audit_type: str, full_reply: str, preview_data: dict,
) -> None:
    """è§£æ LLM å®¡è®¡å›å¤ï¼Œä¿å­˜ç»“æœå¹¶åˆ·æ–°é¡µé¢"""
    should_rerun = False
    with st.status("è§£æå®¡è®¡æŠ¥å‘Š...") as s4:
        parsed = _parse_audit_json(full_reply)

        if parsed:
            st.markdown("**æŠ¥å‘Šç»“æ„:**")
            st.caption(f"- æ•´ä½“é£é™©: {parsed.get('risk_level', 'N/A')}")
            st.caption(f"- å¯ä¿¡åº¦: {parsed.get('confidence_score', 'N/A')}%")
            st.caption(f"- å®¡è®¡é¡¹: {len(parsed.get('audit_items', []))} é¡¹")
            st.caption(f"- çº¢æ——ä¿¡å·: {len(parsed.get('red_flags', []))} ä¸ª")

            audit_result = {
                "report": parsed,
                "raw_response": full_reply,
                "conversation": [],
                "sector_data_snapshot": {
                    "cycle_position": preview_data.get("cycle_analysis", {}).get("overall", {}).get("cycle_position"),
                    "factors_count": len(preview_data.get("factors_config", {}).get("factors", [])),
                    "stocks_count": len(preview_data.get("stock_profiles", {}).get("stocks", [])),
                },
            }
            _save_audit_result(sector, audit_type, audit_result)
            s4.update(label="æŠ¥å‘Šå·²ä¿å­˜", state="complete")
            should_rerun = True
        else:
            st.warning("æœªèƒ½è§£æå‡ºç»“æ„åŒ–æŠ¥å‘Šï¼Œä¿å­˜åŸå§‹å›å¤")
            audit_result = {
                "report": None,
                "raw_response": full_reply,
                "conversation": [],
            }
            _save_audit_result(sector, audit_type, audit_result)
            s4.update(label="å·²ä¿å­˜åŸå§‹å›å¤", state="complete")

    st.session_state.pop(f"_audit_pending_{audit_type}_{sector}", None)
    if should_rerun:
        st.rerun()


# ==================== Tab å†…å®¹æ¸²æŸ“ ====================

def _render_tab_content(
    sector: str,
    audit_type: str,
    preview_data: dict,
    llm_config: LLMConfig,
    all_results: dict,
) -> None:
    """æ¸²æŸ“å•ä¸ªå®¡è®¡ Tab çš„å†…å®¹"""
    type_label = _AUDIT_TYPES.get(audit_type, audit_type)

    # æ•°æ®å®Œæ•´åº¦é¢„è§ˆï¼ˆæŒ‰ç±»å‹æ˜¾ç¤ºä¸åŒæŒ‡æ ‡ï¼‰
    _render_data_preview(audit_type, preview_data)

    # æ£€æŸ¥æ˜¯å¦æ»¡è¶³å®¡è®¡æ¡ä»¶
    can_audit = _check_audit_ready(audit_type, preview_data)

    # å·²æœ‰å®¡è®¡ç»“æœ
    sector_results = all_results.get(sector, {})
    existing = sector_results.get(audit_type)

    if existing:
        report = existing.get("report")
        audited_at = existing.get("audited_at", "")
        time_str = audited_at[:10] if audited_at else ""

        if report:
            risk = report.get("risk_level", "medium")
            risk_label = _RISK_LABELS.get(risk, "æœªçŸ¥")
            confidence = report.get("confidence_score", 0)
            exp_label = f"ä¸Šæ¬¡{type_label}ç»“æœ â€” é£é™©: {risk_label} Â· å¯ä¿¡åº¦ {confidence}% Â· {time_str}"
        else:
            exp_label = f"ä¸Šæ¬¡{type_label}ç»“æœ â€” (åŸå§‹æ–‡æœ¬) Â· {time_str}"

        with st.expander(exp_label, expanded=True):
            if report:
                _render_audit_report(report)
            else:
                st.markdown("**åŸå§‹å®¡è®¡å›å¤:**")
                raw = existing.get("raw_response", "")
                st.markdown(raw)

            # åé¦ˆåŒºåŸŸï¼ˆä»… medium/high/critical æ—¶æ˜¾ç¤ºï¼‰
            if report and report.get("risk_level") in ("medium", "high", "critical"):
                st.markdown("---")
                _render_feedback_action(sector, audit_type, report, llm_config)

            st.markdown("---")
            st.markdown("##### å¯¹è¯è¿½é—®")
            _render_audit_chat(sector, audit_type, llm_config, existing)

    # å®¡è®¡ä»»åŠ¡è½®è¯¢ï¼ˆåœ¨æŒ‰é’®ä¹‹å‰æ£€æŸ¥ï¼Œé˜²æ­¢ rerun åä»»åŠ¡ä¸¢å¤±ï¼‰
    if can_audit:
        from quant.dashboard.bg_task import has_task
        audit_task_id = f"audit_{audit_type}_{sector}"
        audit_active = has_task(audit_task_id)
        audit_pending_key = f"_audit_pending_{audit_type}_{sector}"

        # æ´»è·ƒä»»åŠ¡è½®è¯¢ï¼ˆä¼˜å…ˆäºæŒ‰é’®æ¸²æŸ“ï¼‰
        if audit_active or st.session_state.get(audit_pending_key):
            _run_audit(sector, llm_config, audit_type)
            return  # è¿è¡Œä¸­ä¸æ¸²æŸ“æŒ‰é’®

        # å¼€å§‹å®¡è®¡æŒ‰é’®
        btn_label = f"é‡æ–°{type_label}" if existing else f"å¼€å§‹{type_label}"
        if st.button(btn_label, type="primary", key=f"start_{audit_type}_{sector}"):
            st.session_state[audit_pending_key] = True
            st.rerun()
    else:
        st.info(f"æ•°æ®ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œ{type_label}ã€‚è¯·å…ˆå®Œæˆç›¸å…³åˆ†ææ­¥éª¤ã€‚")


def _render_data_preview(audit_type: str, preview_data: dict) -> None:
    """æŒ‰å®¡è®¡ç±»å‹æ˜¾ç¤ºæ•°æ®å®Œæ•´åº¦æŒ‡æ ‡"""
    if audit_type == "factors":
        col1, col2 = st.columns(2)
        has_factors = "factors_config" in preview_data
        factors_count = len(preview_data.get("factors_config", {}).get("factors", [])) if has_factors else 0
        col1.metric("å› å­æ•°é‡", factors_count if has_factors else "æ— ")
        updated = preview_data.get("factors_config", {}).get("updated_at", "æ— ")
        col2.metric("æ›´æ–°æ—¶é—´", updated[:10] if updated and updated != "æ— " else "æ— ")

    elif audit_type == "cycle":
        col1, col2, col3 = st.columns(3)
        has_cycle = "cycle_analysis" in preview_data
        overall = preview_data.get("cycle_analysis", {}).get("overall", {})
        col1.metric("å‘¨æœŸä½ç½®", overall.get("cycle_position", "æ— ") if has_cycle else "æ— ")
        col2.metric("åè½¬æ¦‚ç‡", f"{overall.get('reversal_probability', 0)}%" if has_cycle else "æ— ")
        has_factors = "factors_config" in preview_data
        factors_count = len(preview_data.get("factors_config", {}).get("factors", [])) if has_factors else 0
        col3.metric("å› å­æ•°é‡", factors_count if has_factors else "æ— ")

    elif audit_type == "stock":
        col1, col2 = st.columns(2)
        has_stocks = "stock_profiles" in preview_data
        stock_count = len(preview_data.get("stock_profiles", {}).get("stocks", [])) if has_stocks else 0
        col1.metric("ä¸ªè‚¡æ•°é‡", stock_count if has_stocks else "æ— ")
        # æ£€æŸ¥æ˜¯å¦æœ‰ç›¸å…³æ€§æ•°æ®
        has_corr = False
        if has_stocks:
            for s in preview_data.get("stock_profiles", {}).get("stocks", []):
                if s.get("correlation"):
                    has_corr = True
                    break
        col2.metric("ç›¸å…³æ€§æ•°æ®", "æœ‰" if has_corr else "æ— ")

    else:  # full
        col1, col2, col3, col4 = st.columns(4)
        col1.metric("å› å­é…ç½®", "æœ‰" if "factors_config" in preview_data else "æ— ")
        col2.metric("å‘¨æœŸåˆ†æ", "æœ‰" if "cycle_analysis" in preview_data else "æ— ")
        col3.metric("ä¸ªè‚¡æ¡£æ¡ˆ", "æœ‰" if "stock_profiles" in preview_data else "æ— ")
        col4.metric("å½’æ¡£æ•°æ®", f"{preview_data.get('archive_file_count', 0)} æ–‡ä»¶")


def _check_audit_ready(audit_type: str, preview_data: dict) -> bool:
    """æ£€æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³å¼€å§‹å®¡è®¡çš„æ¡ä»¶"""
    if audit_type == "factors":
        return "factors_config" in preview_data
    elif audit_type == "cycle":
        return "cycle_analysis" in preview_data
    elif audit_type == "stock":
        return "stock_profiles" in preview_data
    else:  # full
        return preview_data.get("found", False)


# ==================== ä¸»é¡µé¢ ====================

def render_audit_page() -> None:
    """æ¸²æŸ“å®¡è®¡é¡µé¢"""
    st.header("å®¡è®¡ â€” AI çº¢é˜Ÿè´¨ç–‘")
    st.markdown("ç‹¬ç«‹å®¡è®¡ agent æ·±åº¦è´¨ç–‘åˆ†æç»“è®ºï¼Œè¯†åˆ«æ•°æ®é£é™©ä¸é€»è¾‘æ¼æ´ã€‚")

    # æ£€æŸ¥å®¡è®¡ LLM é…ç½®
    audit_config = get_audit_llm_config()
    if audit_config is None:
        st.warning("è¯·å…ˆåœ¨ã€Œè®¾ç½®ã€é¡µé¢é…ç½® LLM API Keyï¼ˆä¸» LLM æˆ–ç‹¬ç«‹å®¡è®¡æ¨¡å‹å‡å¯ï¼‰ã€‚")
        st.info("å»ºè®®ä½¿ç”¨ DeepSeek-V3 æˆ–å…¶ä»–å¼ºæ¨ç†æ¨¡å‹ä½œä¸ºå®¡è®¡ agentã€‚")
        return

    # åŠ è½½å·²åˆ†ææ¿å—
    sectors = []
    if CYCLE_DATA_PATH.exists():
        try:
            with open(CYCLE_DATA_PATH, "r", encoding="utf-8") as f:
                cycle_data = json.load(f)
                sectors = list(cycle_data.keys())
        except Exception:
            pass

    # ä¹Ÿæ£€æŸ¥åªæœ‰å› å­é…ç½®çš„æ¿å—
    if FACTORS_PATH.exists():
        try:
            with open(FACTORS_PATH, "r", encoding="utf-8") as f:
                factor_sectors = list(json.load(f).keys())
                for s in factor_sectors:
                    if s not in sectors:
                        sectors.append(s)
        except Exception:
            pass

    if not sectors:
        st.info("æš‚æ— å·²åˆ†æçš„æ¿å—ã€‚è¯·å…ˆåˆ°ã€Œå› å­é…ç½®ã€æˆ–ã€Œå‘¨æœŸåˆ†æã€é¡µé¢åˆ†æè‡³å°‘ä¸€ä¸ªæ¿å—ã€‚")
        return

    # æ¿å—é€‰æ‹©
    selected_sector = st.selectbox(
        "é€‰æ‹©è¦å®¡è®¡çš„æ¿å—",
        sectors,
        help="ä»å·²å®Œæˆåˆ†æçš„æ¿å—ä¸­é€‰æ‹©",
    )

    if not selected_sector:
        return

    # åŠ è½½æ•°æ®
    preview_data = _load_sector_complete_data(selected_sector)
    all_results = _load_audit_results()

    # Tab å¸ƒå±€
    tab_factors, tab_cycle, tab_stock, tab_full = st.tabs([
        "å› å­å®¡è®¡", "å‘¨æœŸå®¡è®¡", "ä¸ªè‚¡å®¡è®¡", "å…¨é¢å®¡è®¡",
    ])

    with tab_factors:
        _render_tab_content(selected_sector, "factors", preview_data, audit_config, all_results)

    with tab_cycle:
        _render_tab_content(selected_sector, "cycle", preview_data, audit_config, all_results)

    with tab_stock:
        _render_tab_content(selected_sector, "stock", preview_data, audit_config, all_results)

    with tab_full:
        _render_tab_content(selected_sector, "full", preview_data, audit_config, all_results)
